NAME: Meiyi Zheng
EMAIL: meiyizheng@g.ucla.edu
ID: 605147145

File Description:

lab2_list.c: a C program that implements the specified command line options (--threads, --iterations, --yield, --sync, --lists), drives one or more parallel threads that do operations on a shared linked list, and reports on the final list and performance
SortedList.h: a header file describing the interfaces for linked list operations.
SortedList.c: a C module that implements insert, delete, lookup and length methods for a sorted linked list.
Makefile: a makefile to build the deliverable program, output, graphs, and tarball. The targets are: build, tests, graphs, profile, dist, clean.
lab2b_list.csv: contaning all of the results for all of the Part-2 tests.
graphs(.png files):
lab2b_1.png ... throughput vs. number of threads for mutex and spin-lock synchronized list operations.
lab2b_2.png ... mean time per mutex wait and mean time per operation for mutex-synchronized list operations.
lab2b_3.png ... successful iterations vs. threads for each synchronization method.
lab2b_4.png ... throughput vs. number of threads for mutex synchronized partitioned lists.
lab2b_5.png ... throughput vs. number of threads for spin-lock-synchronized partitioned lists.
README: a file containnig the file descriptions and answers to the questions.


Question and Answer:

QUESTION 2.3.1 - CPU time in the basic list implementation:
Where do you believe most of the CPU time is spent in the 1 and 2-thread list tests ?

Why do you believe these to be the most expensive parts of the code?

Where do you believe most of the CPU time is being spent in the high-thread spin-lock tests?

Where do you believe most of the CPU time is being spent in the high-thread mutex tests?

Answer:
Most of the CPU time in 1 and 2-thread list tests will be spent on the list operations: insert, length, lookup, delete. But for the spin lock, there is a significant time spent on spinning, because each time it waits for a lock, it just keep spinning, which will waste the CPU time. However, for the mutex lock, each time it waits for a lock, it just put to sleep, and not waste CPU time, so most of the time is spent on list operations.

As the number of thread increase, the race condition increases. For spin lock, most of the CPU time is being spent on spinning. For mutex, most of the CPU time is being spent on list operations.

QUESTION 2.3.2 - Execution Profiling:
Where (what lines of code) are consuming most of the CPU time when the spin-lock version of the list exerciser is run with a large number of threads?

Why does this operation become so expensive with large numbers of threads?

Answer:
Like the previous answer, the spinning consume more than 90% of the CPU time.
As the number of threads increase, only one thread can do list operaions at a given time, the rest threads are waiting for the lock, so the waiting time keep increasing.

QUESTION 2.3.3 - Mutex Wait Time:
Look at the average time per operation (vs. # threads) and the average wait-for-mutex time (vs. #threads).
Why does the average lock-wait time rise so dramatically with the number of contending threads?
Why does the completion time per operation rise (less dramatically) with the number of contending threads?
How is it possible for the wait time per operation to go up faster (or higher) than the completion time per operation?

Answer:
The average wait time increases because there is only one thread can do the work while others are waiting.

The completion time per operations increases because there is overhead to put threads into sleep and wake them up, which will increases the total completion time.

It is possible that the wait time per operation is greater than the completion time per operation because the wait time per operation is for individual thread, while the completion time per operation is for all threads.

QUESTION 2.3.4 - Performance of Partitioned Lists
Explain the change in performance of the synchronized methods as a function of the number of lists.
Should the throughput continue increasing as the number of lists is further increased? If not, explain why not.
It seems reasonable to suggest the throughput of an N-way partitioned list should be equivalent to the throughput of a single list with fewer (1/N) threads. Does this appear to be true in the above curves? If not, explain why not.

Answer:
The performance increase as the number of sublists increases. When there are not many lists, the contention for lists is high because there is only one thread can work on it at a time. But as the number of lists increases, more threads can work on the lists at a time because different sublists have their individual locks.

The throughput will continue increasing as the number of lists is further increased. Because there will be a point when the overhead of creating a list is greater the performance benefit of reducing contention.

No. When we partition the list into sublists, the length of each list is shortened. When the threads is doing list operations, the lock wait time is shorteded because there are fewer operations to wait for. This will increase the performance. Reducing the threads is not the exact case of this situation. 